Model Restructure

Schema: (Supply_ID, Time_interval, Feature1, Feature2, ... ..., Label)

Idea: Determine time intervals to which, for each corresponding Supply_ID, will have its characteristic features (need to be defined)


Time interval: 
    - First idea: synchronize intervals, as in same dates (Very unlikely to be possible)
    - Second idea: Organize intervals by supply history. In more detail, each interval has the same length and is ordered according to time.
        For example: Each interval represents a week of a supply. First interval is the first week of available data of this supply. Second interval is the second week and so on.
        Each interval will not be synchronized by dates, but will be synchronized by order in which it happened to that supply

        Example dataset:

        Supply_ID, Interval, Feature1, Label

            0       0                   Fraud
            0       1                   Fraud
            0       2                   Fraud
            1       0                   Regular
            1       1                   Regular
            1       2
            2       0
            2       1   
            2       2
            3       0
            3       1   
            3       2

Implementing second idea:
    - Select time interval: Yearly (for now)
    - Select which datasets to use: Works , Consumption, Customer info and Interruptions (Add more later)
    - For each data set group information by supply per year

        Consumption: 
            RangeIndex: 511 entries, 0 to 510
            Data columns (total 6 columns):
            #   Column     Non-Null Count  Dtype  
            ---  ------     --------------  -----  
            0   Supply_ID  511 non-null    object 
            1   meas_ym    511 non-null    int64  
            2   val_mean   511 non-null    float64
            3   val_max    511 non-null    float64
            4   val_min    511 non-null    float64
            5   val_std    511 non-null    float64
            dtypes: float64(4), int64(1), object(1)
            memory usage: 24.1+ KB
            None

            entries per supply: Supply_ID
            SUPPLY001    2
            SUPPLY002    5
            SUPPLY003    5
            SUPPLY004    5
            SUPPLY005    5
                        ..
            SUPPLY096    5
            SUPPLY097    6
            SUPPLY098    6
            SUPPLY099    5
            SUPPLY100    5
            Length: 100, dtype: int64

            max entries: 6
            min entries: 2
            mean entries: 5.11

        Customer info:
            For customer info also group 

            For this dataset I want to do something similar. I still want to group the data by supply and year, but instead of computing some 
            function on this data I want to have a column indicating if in that year the supply was active, terminated, fictitious or mixed (cases where in that year supply was more than only one of these categories).
            I want the end schema to look like: (Supply_ID, Year, Available_power, Status) where status indicates A for active, C for terminated, F for fictitious and M for mixed

            For tomorrow: Decide what to do with null values (set everything to 0), so stats on available power can be computed
            Try both and see how much data is lost
            Null values set to 0

        Works: 
            FELIPE

        Interruptions:
            FELIPE

        Status_words:
            FELIPE

    Merging datasets:
        
        There are clear gaps between datasets. Objective is to keep as much information as possible
         which means filling some features with 0s where data is not available

        How periods will work: Periods won`t be synchronized but will represent the ordered history of that supplly.
        So for example if it is decided 5 periods, for each supply these will be the first 5 years of data logged.

        How to find best number of periods?
        First find supply with the least number of years. (using consumption as a basis)
        In consumption there are supplies with only 2 years and max of 6 years and mean is 5 years.
        Begin by using 6 periods (years) and fill in with 0s supplies that don`t contain enough data.

        Consumption:
        NaN values per column:
            Supply_ID     0
            meas_ym       0
            val_mean     89
            val_max      89
            val_min      89
            val_std      89
            dtype: int64

            Non NaN values per column:
            Supply_ID    600
            meas_ym      600
            val_mean     511
            val_max      511
            val_min      511
            val_std      511


        Now based on the consumption years, extract the same from other datasets.
        
        Customer_info:
        Based on years extracted by consumption data filter rows of corresponding years and add empty rows in the case year not present.
        Now check if dataset correctly Processed.

                NaN values per column:
        Supply_ID                 0
        Year                      0
        mean_available_power    106
        Status                  106
        Status_encoded          106
        dtype: int64

        Non NaN values per column:
        Supply_ID               600
        Year                    600
        mean_available_power    494
        Status                  494
        Status_encoded          494

    Consumption and Customer_info merge:
                NaN values per column:
        Supply_ID                 0
        Year                      0
        val_mean                 94
        val_max                  94
        val_min                  94
        val_std                  94
        mean_available_power    106
        Status                  106
        Status_encoded          106
        dtype: int64

        Non NaN values per column:
        Supply_ID               600
        Year                    600
        val_mean                506
        val_max                 506
        val_min                 506
        val_std                 506
        mean_available_power    494
        Status                  494
        Status_encoded          494
        dtype: int64


    Up next: Process other datasets to make final merge. Then with final merge prepare data to train XGboost model.
    
    Skipped into testing created dataset with consumption and customer info on XGboost:
        - Label the created dataset
        - Pre-processing:
            Handle Nans, handle possible imbalance. 
            Fill NaNs with column mean. Drop rows that contain more than 3 0 values.
        - Create XGboost classifier
 ======= FOR LATER ========
Analyse model and see what improvements can be made:
    - Check label balance
    - splitted correctly
    - Final dataset size 
    - Hyperparameters
    - Dont drop Supply_ID

